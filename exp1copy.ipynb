{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import os, pickle, gzip\n",
    "from PIL import Image\n",
    "\n",
    "from theano import function\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def shared_dataset(data_xy):\n",
    "    data_x, data_y = data_xy\n",
    "    shared_x = theano.shared(np.asarray(data_x, dtype=theano.config.floatX))\n",
    "    shared_y = theano.shared(np.asarray(data_y, dtype=theano.config.floatX))\n",
    "\n",
    "    return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "test_set_x, test_set_y = shared_dataset(test_set)\n",
    "valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "data = train_set_x[2 * batch_size: 3 * batch_size]\n",
    "label = train_set_y[2 * batch_size: 3 * batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "\n",
    "        self.W = theano.shared(\n",
    "            value=np.zeros(\n",
    "                (n_in, n_out),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='W',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "        self.b = theano.shared(\n",
    "            value=np.zeros(\n",
    "                (n_out,),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)\n",
    "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "        self.params = [self.W, self.b]\n",
    "        self.input = input\n",
    "\n",
    "    def negative_log_likelihood(self, y):\n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "\n",
    "    def errors(self, y):\n",
    "        return T.mean(T.neq(self.y_pred, y))\n",
    "\n",
    "def sgd_optimization_mnist(learning_rate=0.13, n_epoches=1000,\n",
    "                           batch_size=600):\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "    n_test_batches = test_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "\n",
    "    index = T.lscalar()\n",
    "\n",
    "    x = T.matrix('x')\n",
    "    y = T.ivector('y')\n",
    "\n",
    "    classifier = LogisticRegression(input=x, n_in=28*28, n_out=10)\n",
    "\n",
    "    cost = classifier.negative_log_likelihood(y)\n",
    "\n",
    "    test_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: test_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    validate_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    g_W = T.grad(cost=cost, wrt=classifier.W)\n",
    "    g_b = T.grad(cost=cost, wrt=classifier.b)\n",
    "\n",
    "    updates = [(classifier.W, classifier.W - learning_rate * g_W),\n",
    "               (classifier.b, classifier.b - learning_rate * g_b)]\n",
    "\n",
    "    train_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    epoch = 0\n",
    "    while epoch < n_epoches:\n",
    "        epoch = epoch + 1\n",
    "        for minibatch_index in range(n_train_batches):\n",
    "            minibatch_avg_cost = train_model(minibatch_index)\n",
    "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = sgd_optimization_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "def predict(classifier):\n",
    "    predict_model = theano.function(\n",
    "        inputs=[classifier.input],\n",
    "        outputs=classifier.y_pred\n",
    "    )\n",
    "\n",
    "    predicted_values = predict_model(test_set_x.eval())\n",
    "    return predicted_values\n",
    "\n",
    "predicted_value = predict(classifier)\n",
    "test_y = test_set_y.eval()\n",
    "np.count_nonzero(predicted_value != test_y)\n",
    "print(predicted_value.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_digit(image):\n",
    "    img = Image.fromarray(np.uint8(image), 'L')\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/lzx/OneDrive/Projects/untitled folder')\n",
    "train_images, train_labels = read_data('train-images-idx3-ubyte', 'train-labels-idx1-ubyte')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N = len(train_images)\n",
    "N_row, N_col = np.shape(train_images)\n",
    "N_feats = N_row * N_col\n",
    "N_hidden = 768\n",
    "x = T.matrix('x')\n",
    "y = T.matrix('y')\n",
    "W = theano.shared(np.random.randn(N_feats, N_hidden), name='w')\n",
    "a = theano.shared(np.random.randn(N_hidden,10), name='a')\n",
    "f = T.dot(a, abs(T.dot(W, x)))# / np.sqrt(N_hidden)\n",
    "score = T.nnet.softmax(f)\n",
    "prediction = T.argmax(score)\n",
    "loss = ((y - f) ** 2).sum()\n",
    "gW = T.grad(loss, W)\n",
    "\n",
    "train = theano.function(\n",
    "    inputs = [x, y],\n",
    "    outputs = []\n",
    ")\n",
    "# b = theano.shared(0., name='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Exp]",
   "language": "python",
   "name": "conda-env-Exp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
